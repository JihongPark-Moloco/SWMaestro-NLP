import bs4
import pandas as pd
import re
import psycopg2 as pg2
import numpy as np
import pandas as pd

from krwordrank.word import KRWordRank


# ëŒ“ê¸€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def pre(text):
    text = text.strip().lower()
    # text = re.sub('[^ 0-9ã„±-ã…£ê°€-í£a-z:/_.\'\",~!?`#%^&*{}()]+', '', text)
    text = re.sub('http.*', '', text)
    text = re.sub('[0-9]{1,3}:[0-9]{1,2}', ' ', text)
    # text = re.sub('[^ 0-9ã„±-ã…£ê°€-í£a-z!?.,\'\"~`#%^&*(){}]+', ' ', text)
    text = re.sub('[^ 0-9ã„±-ã…£ê°€-í£a-z#]', ' ', text)
    text = re.sub('\n', ' ', text)
    text = re.sub(' {2,}', ' ', text)
    return text.strip()


# ëŒ“ê¸€ ì…ë ¥ì‹œ í‚¤ì›Œë“œë¥¼ ì¶œë ¥í•œë‹¤
def do_wr_keyword(video_name, video_description, comments):
    min_count = 2  # ë‹¨ì–´ì˜ ìµœì†Œ ì¶œí˜„ ë¹ˆë„ìˆ˜ (ê·¸ë˜í”„ ìƒì„± ì‹œ)
    max_length = 10  # ë‹¨ì–´ì˜ ìµœëŒ€ ê¸¸ì´
    wordrank_extractor = KRWordRank(min_count=min_count, max_length=max_length, verbose=True)

    beta = 0.85  # PageRankì˜ decaying factor beta
    max_iter = 10
    keywords, rank, graph = wordrank_extractor.extract([video_name, video_description] + comments, beta, max_iter)

    exact_keys = re.findall('#[ã„±-ã…£ê°€-í£a-zA-Z0-9]+', video_description)

    # main_sentence = ''.join(plus_comments)
    print("#### wordrank, ì˜ìƒ ì„¤ëª…ì— í¬í•¨ëœ í‚¤ì›Œë“œ ####")
    print(exact_keys)

    print("#### wordrank, ì œëª© ë° ì„¤ëª… í¬í•¨ í‚¤ì›Œë“œ ëª©ë¡ ####")
    for word, r in sorted(keywords.items(), key=lambda x: x[1], reverse=True):
        if word in video_name or word in video_description:
            print('%8s:\t%.4f' % (word, r))

    print("#### wordrank, ì „ì²´ í‚¤ì›Œë“œ ëª©ë¡ ####")

    for word, r in sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:30]:
        print('%8s:\t%.4f' % (word, r))


conn = pg2.connect(database="createtrend", user="muna", password="muna112358!", host="222.112.206.190",
                   port="5432")
cur = conn.cursor()

cur.execute(f'SELECT idx, channel_id FROM channel;')
channel_id_list = cur.fetchall()

for idx, channel_id in channel_id_list:
    idx = 530
    cur.execute(f"""
SELECT A.idx, A.video_name, A.video_description, B.views
FROM video A
         LEFT JOIN (SELECT DISTINCT ON (video_idx) video_idx, check_time, views
                    FROM video_views
                    ORDER BY video_idx, check_time DESC) B
                   ON A.idx = B.video_idx
WHERE A.channel_idx = {idx}
  AND A.forbidden = FALSE;
""")
    video_list = pd.DataFrame(cur.fetchall())
    views = video_list[3]
    np.average(views)

cur.execute(f'SELECT idx, video_name, video_description FROM video WHERE idx=63041;')
video_idx, video_name, video_description = cur.fetchall()[0]

cur.execute(f"SELECT comment_content FROM comment WHERE video_idx={video_idx};")
comments = [pre(c[0]) for c in cur.fetchall()]

do_wr_keyword(pre(video_name), pre(video_description), comments)

conn.close()
#
# comments = [pre(''.join(div.find("p").text).strip()) for div in all_divs if
#             pre(''.join(div.find("p").text).strip()) != '']
# ori_comments = [''.join(div.text.split('\n')[1:]).strip() for div in all_divs]
#
# # ì œëª©ê³¼ ì˜ìƒ ì„¤ëª… ë¦¬ìŠ¤íŠ¸
# plus_data = ["""
# [ë¬´í•œë„ì „] ((ë¬´í•œìƒì‚¬)) ë©Xì´ = ì•½ê°„..ëª¨ìë¼ì§€ë§Œ ì°©í•œ ì¹œêµ¬ì•¼! (=^_^=) í•˜ë£¨ì— 400ë²ˆì”© í•˜ëŠ”(?) ë‚˜ìœ ë§ ê³ ì¹˜ê¸° íŠ¹ê°• ğŸ‘©â€ğŸ«
# """, """
# ê³µì‹í™ˆí˜ì´ì§€  http://www.imbc.com/broad/tv/ent/chal...
# ë°©ì†¡ì‹œê°„  SAT 18:30~
# Infinite Challenge(ë¬´í•œë„ì „), EP270, 2011/10/08, MBC TV, Republic of Korea
#
# ë°°í˜„ì§„ ì•„ë‚˜ìš´ì„œì™€ ê³ ìš´ë§ ì“°ê¸° íŠ¹ê°•
# """]
#
# plus_comments = [pre(text.strip()) for text in plus_data]
# comments += plus_comments
# do_wr_keyword(comments, plus_comments)
